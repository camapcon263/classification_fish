{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\data\\\\Fish_Dataset\"\n",
    "output_folder = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\clustering\\\\data\\\\Fish_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder names\n",
    "folder_names = ['Black Sea Sprat', 'Gilt Head Bream', 'Hourse Mackerel', 'Red Mullet',\n",
    "               'Red Sea Bream', 'Sea Bass', 'Shrimp', 'Striped Red Mullet', 'Trout']\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(output_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(path_data)\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path_data, folder, folder)\n",
    "    k = 1\n",
    "    for i in range (1, 1001, 20):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "        img_save = os.path.join(output_folder, folder, f\"{str(k).zfill(5)}.png\")\n",
    "        img = Image.open(img_path)\n",
    "        resized_img = img.resize((128, 128), resample=Image.BICUBIC) # thay đổi giá trị của new_width, new_height và resample tùy ý\n",
    "        resized_img.save(img_save)\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\data\\\\NA_Fish_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(path_data)\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path_data, folder)\n",
    "    k = 51\n",
    "    # if folder == \"Trout\":\n",
    "    #     for i in range (1, 31):\n",
    "    #         img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "    #         img_save = os.path.join(output_folder, folder, f\"{str(k).zfill(5)}.png\")\n",
    "    #         img = Image.open(img_path)\n",
    "    #         resized_img = img.resize((128, 128), resample=Image.BICUBIC) # thay đổi giá trị của new_width, new_height và resample tùy ý\n",
    "    #         resized_img.save(img_save)\n",
    "    #         k = k + 1\n",
    "    # else:\n",
    "    for i in range (1, 51):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "        img_save = os.path.join(output_folder, folder, f\"{str(k).zfill(5)}.png\")\n",
    "        img = Image.open(img_path)\n",
    "        resized_img = img.resize((128, 128), resample=Image.BICUBIC) # thay đổi giá trị của new_width, new_height và resample tùy ý\n",
    "        resized_img.save(img_save)\n",
    "        k = k + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = label(y_true_in > 0.5)\n",
    "    y_pred = label(y_pred_in > 0.5)\n",
    "    \n",
    "    true_objects = len(np.unique(labels))\n",
    "    pred_objects = len(np.unique(y_pred))\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.array(np.mean(metric), dtype=np.float32)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    metric_value = tf.py_function(iou_metric_batch, [label, pred], tf.float32)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\clustering\\\\data\\\\Fish_Dataset\"\n",
    "images = [] # mảng chứa dữ liệu\n",
    "folders = os.listdir(path)\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    for i in range(1, 101):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "        # print(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 128, 128, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder = 'D:\\\\study\\\\machine_learning\\\\classification_fish\\\\clustering\\\\data\\\\Fish_Dataset_GT'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder names\n",
    "folder_names = ['Black Sea Sprat', 'Gilt Head Bream', 'Hourse Mackerel', 'Red Mullet',\n",
    "               'Red Sea Bream', 'Sea Bass', 'Shrimp', 'Striped Red Mullet', 'Trout']\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(output_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('D:\\\\study\\\\machine_learning\\\\classification_fish\\\\model\\\\unet_1.hdf5', \n",
    "                   custom_objects={'my_iou_metric': my_iou_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 17s 603ms/step\n"
     ]
    }
   ],
   "source": [
    "img = model.predict(images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gt = np.squeeze(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the images\n",
    "for i in range(len(img_gt)):\n",
    "    # Get the folder name and image index\n",
    "    folder_index = i // 100\n",
    "    folder_name = folder_names[folder_index]\n",
    "    image_index = i % 100\n",
    "\n",
    "    # Format the image index as a 5-digit string\n",
    "    image_index_str = str(image_index + 1).zfill(5)\n",
    "\n",
    "    # Create the file name\n",
    "    filename = f'{image_index_str}.png'\n",
    "\n",
    "    # Convert the predicted array to a binary image\n",
    "    img_binary = (img_gt[i] > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Create the image object from the binary array\n",
    "    pred_image = Image.fromarray(img_binary, mode='L')\n",
    "\n",
    "    # Save the image to the corresponding folder\n",
    "    folder_path = os.path.join(output_folder, folder_name)\n",
    "    output_path = os.path.join(folder_path, filename)\n",
    "    pred_image.save(output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\clustering\\\\data\\\\Fish_Dataset\"\n",
    "path_gt = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\clustering\\\\data\\\\Fish_Dataset_GT\"\n",
    "output_folder = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\clustering\\\\data\\\\Fish_Dataset_Segment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder names\n",
    "folder_names = ['Black Sea Sprat', 'Gilt Head Bream', 'Hourse Mackerel', 'Red Mullet',\n",
    "               'Red Sea Bream', 'Sea Bass', 'Shrimp', 'Striped Red Mullet', 'Trout']\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(output_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Black Sea Sprat\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Black Sea Sprat\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Gilt Head Bream\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Gilt Head Bream\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Hourse Mackerel\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Hourse Mackerel\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Red Mullet\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Red Mullet\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Red Sea Bream\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Red Sea Bream\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Sea Bass\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Sea Bass\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Shrimp\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Shrimp\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Striped Red Mullet\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Striped Red Mullet\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset\\Trout\n",
      "D:\\study\\machine_learning\\classification_fish\\clustering\\data\\Fish_Dataset_GT\\Trout\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(path_img)\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path_img, folder)\n",
    "    folder_gt = os.path.join(path_gt, folder)\n",
    "    print(folder_path)\n",
    "    print(folder_gt)\n",
    "    for i in range(1, 101):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "        mask_path = os.path.join(folder_gt, f\"{str(i).zfill(5)}.png\")\n",
    "        # đọc ảnh\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = cv2.resize(mask, (128, 128))\n",
    "\n",
    "        # Chuyển ảnh mask sang ảnh binary\n",
    "        gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Tìm contours trên ảnh binary\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # Lặp qua từng contour\n",
    "        for contour in contours:\n",
    "            # Tìm bounding box của contour\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Kiểm tra kích thước bounding box\n",
    "            if w > 25 and h > 25:\n",
    "                # Kiểm tra màu của pixel tương ứng trên ảnh ground truth\n",
    "                if mask[y:y+h, x:x+w].max() == 255:\n",
    "                    # Lấy phần ảnh tương ứng từ ảnh gốc\n",
    "                    obj = cv2.bitwise_and(img[y:y+h, x:x+w], mask[y:y+h, x:x+w])\n",
    "                    # Lưu ảnh vào thư mục D:\\study\\machine_learning\\classification_fish\\data\\NA_Fish_Dataset\\ folder\n",
    "                    cv2.imwrite(f\"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\clustering\\\\data\\\\Fish_Dataset_Segment\\\\{folder}\\\\{str(i).zfill(5)}.png\", obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
