{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import thư viện\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\study-hk2\\\\ML\\\\ML\\\\classification_fish\\\\data\\\\Fish_Dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1001\u001b[39m):\n\u001b[0;32m      6\u001b[0m     img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder_path, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(i)\u001b[39m.\u001b[39mzfill(\u001b[39m5\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(img_path)\n\u001b[0;32m      9\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     10\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = [] # mảng chứa dữ liệu\n",
    "folders = os.listdir(path)\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path, folder, folder)\n",
    "    for i in range(1, 1001):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        data.append([img, folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [] # mảng chứa dữ liệu\n",
    "folders = os.listdir(path)\n",
    "for folder in folders:\n",
    "    folder_gt = folder + \" GT\"\n",
    "    folder_path = os.path.join(path, folder, folder_gt)\n",
    "    for i in range(1, 1001):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        masks.append(img)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "# path = \"D:\\\\study\\\\machine_learning\\\\classification_fish\\\\data\\\\NA_Fish_Dataset\"\n",
    "path1 = 'D:\\\\study-hk2\\\\ML\\\\ML\\\\classification_fish\\\\data\\\\NA_Fish_Dataset'\n",
    "folders = os.listdir(path1)\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path1, folder)\n",
    "    num_images = len(os.listdir(folder_path))  # Đếm số lượng ảnh trong thư mục\n",
    "    for i in range(1, num_images + 1):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        data_test.append([img, folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "names = []\n",
    "\n",
    "for image, name in data_test:\n",
    "    images.append(image)\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Black Sea Sprat\n",
      "1 Gilt Head Bream\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# in ra label và tên tương ứng\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m9\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     \u001b[39mprint\u001b[39m(i, le\u001b[39m.\u001b[39;49mclasses_[i])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "# chuấn hóa label thành dạng số\n",
    "le = LabelEncoder()\n",
    "names = le.fit_transform(names)\n",
    "\n",
    "# in ra label và tên tương ứng\n",
    "for i in range(9):\n",
    "    print(i, le.classes_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "masks = np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = masks.reshape(9000, 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = masks.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = label(y_true_in > 0.5)\n",
    "    y_pred = label(y_pred_in > 0.5)\n",
    "    \n",
    "    true_objects = len(np.unique(labels))\n",
    "    pred_objects = len(np.unique(y_pred))\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.array(np.mean(metric), dtype=np.float32)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    metric_value = tf.py_function(iou_metric_batch, [label, pred], tf.float32)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('D:\\\\study-hk2\\\\ML\\\\ML\\\\classification_fish\\\\model\\\\unet_1.hdf5', \n",
    "                   custom_objects={'my_iou_metric': my_iou_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 94s 331ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (preds > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_gt = \"D:\\\\study-hk2\\\\ML\\\\ML\\\\classification_fish\\\\data\\\\Fish_Dataset_GT\"\n",
    "if not os.path.exists(path_gt):\n",
    "    os.makedirs(path_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder names\n",
    "folder_names = ['Black Sea Sprat', 'Gilt Head Bream', 'Hourse Mackerel', 'Red Mullet',\n",
    "               'Red Sea Bream', 'Sea Bass', 'Shrimp', 'Striped Red Mullet', 'Trout']\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(path_gt, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.squeeze(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Iterate through the images\n",
    "for i in range(len(preds)):\n",
    "    # Get the folder name and image index\n",
    "    folder_index = i // 1000\n",
    "    folder_name = folder_names[folder_index]\n",
    "    image_index = i % 1000\n",
    "\n",
    "    # Format the image index as a 5-digit string\n",
    "    image_index_str = str(image_index + 1).zfill(5)\n",
    "\n",
    "    # Create the file name\n",
    "    filename = f'{image_index_str}.png'\n",
    "\n",
    "    # Convert the predicted array to a binary image\n",
    "    img_binary = (preds[i] > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Create the image object from the binary array\n",
    "    pred_image = Image.fromarray(img_binary, mode='L')\n",
    "\n",
    "    # Save the image to the corresponding folder\n",
    "    folder_path = os.path.join(path_gt, folder_name)\n",
    "    output_path = os.path.join(folder_path, filename)\n",
    "    pred_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = \"D:\\\\study-hk2\\\\ML\\\\ML\\\\classification_fish\\\\data\\\\Fish_Dataset\"\n",
    "path_gt = \"D:\\\\study-hk2\\\\ML\\\\ML\\\\classification_fish\\\\data\\\\Fish_Dataset_GT\"\n",
    "output_folder = \"D:\\\\study-hk2\\\\ML\\\\ML\\\\classification_fish\\\\data\\\\Fish_Dataset_Segment1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder names\n",
    "folder_names = ['Black Sea Sprat', 'Gilt Head Bream', 'Hourse Mackerel', 'Red Mullet',\n",
    "               'Red Sea Bream', 'Sea Bass', 'Shrimp', 'Striped Red Mullet', 'Trout']\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(output_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Black Sea Sprat\\Black Sea Sprat\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Black Sea Sprat\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Gilt Head Bream\\Gilt Head Bream\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Gilt Head Bream\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Hourse Mackerel\\Hourse Mackerel\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Hourse Mackerel\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Red Mullet\\Red Mullet\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Red Mullet\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Red Sea Bream\\Red Sea Bream\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Red Sea Bream\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Sea Bass\\Sea Bass\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Sea Bass\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Shrimp\\Shrimp\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Shrimp\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Striped Red Mullet\\Striped Red Mullet\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Striped Red Mullet\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset\\Trout\\Trout\n",
      "D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_GT\\Trout\n"
     ]
    }
   ],
   "source": [
    "folders = os.listdir(path_img)\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(path_img, folder, folder)\n",
    "    folder_gt = os.path.join(path_gt, folder)\n",
    "    print(folder_path)\n",
    "    print(folder_gt)\n",
    "    for i in range(1, 1001):\n",
    "        img_path = os.path.join(folder_path, f\"{str(i).zfill(5)}.png\")\n",
    "        mask_path = os.path.join(folder_gt, f\"{str(i).zfill(5)}.png\")\n",
    "\n",
    "        # đọc ảnh\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = cv2.resize(mask, (128, 128))\n",
    "\n",
    "        # Chuyển ảnh mask sang ảnh binary\n",
    "        gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Tìm contours trên ảnh binary\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # Lặp qua từng contour\n",
    "        for contour in contours:\n",
    "            # Tìm bounding box của contour\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Kiểm tra kích thước bounding box\n",
    "            if w > 5 and h > 5:\n",
    "                # Kiểm tra màu của pixel tương ứng trên ảnh ground truth\n",
    "                if mask[y:y+h, x:x+w].max() == 255:\n",
    "                    # Lấy phần ảnh tương ứng từ ảnh gốc\n",
    "                    obj = cv2.bitwise_and(img[y:y+h, x:x+w], mask[y:y+h, x:x+w])\n",
    "                    # Lưu ảnh vào thư mục D:\\study\\machine_learning\\classification_fish\\data\\NA_Fish_Dataset\\ folder\n",
    "                    cv2.imwrite(f\"D:\\study-hk2\\ML\\ML\\classification_fish\\data\\Fish_Dataset_Segment1\\\\{folder}\\\\{str(i).zfill(5)}.png\", obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
